**Что происходит после запуска программы?**
Первым делом инициализируется пакет `runtime` который заведует всеми обвязками вокруг нашей программы и в частности он управляет и планировщиком.  Далее `runtime` инициализирует процессоры горутин `Processor(P)`, процессоров будет столько, сколько ядер `runtimeNumCPU()`. Также программа создает необходимое количество тредов ОС: 1 системный тред для sysmon для полезной работы и по 1 треду на процессор.
**Handoff**
Когда у нас выполняется `syscall`, то блокируется не только горутина, но и сам тред, тогда создается новый тред, который передается процессору, а старый уходит в ожидание. 
![[Pasted image 20250807161551.png]]
**Как работает планировщик Golang?**
Есть два пространства памяти: `user space` и `kernel space`, где `user space` - это пространство нашей программы (и в принципе различных процессов), а `kernel space` - это пространство ядра ОС.
![[Pasted image 20250807162945.png]]

Главнейший интерфейс для запуска кода на ядрах процессора, который ОС даёт процессам - это потоки исполнения (треды). За них отвечает планировщик ОС.

Планировщик рантайма Go работает по GMP модели, где G - это горутина (что исполняем), M - machine (машинные треды, где исполняем) и P - Processor (структура в коде планировщика).

У P есть локальная очередь горутин, есть отдельный слот и свой тред. Также есть глобальная очередь (она защищена мьютексом, т.к. с ней работают все процессоры), некоторые треды, занимающиеся `sync syscall` (синхронными системными вызовами) и `netpoller`.
![[Снимок экрана 2025-08-07 в 16.34.57.png]]
**Планирование работы:**
Что будет с "жадной" горутиной (которая работает дольше 10ms)? Такую горутину планировщик отправит в конец глобальной очереди.
Что будет с новой горутиной? Первым делом горутина помещается в слот и наследует время исполнения родительской горутины, если в слоте что-то было, это отправляем в конец локальной очереди, если локальная очередь заполнилась (размер 256), тогда отправляем половину очереди (вроде с конца) в глобальную очередь.

**`Syscalls`** (чтение файла, хождение в сеть):
Бывают синхронные (блокируют тред, пока не выполнятся до конца) и асинхронные (не блокируют тред).

Когда горутина делает синхронный `syscall`, P отвязывает от себя горутину и тред и создаёт для себя новый тред на котором может запускать новые горутины. Когда синхронный `syscall` завершится, горутина ищет свободный процессор, если таких нет, то попадает в конец глобальной очереди (эта процедура называется `handoff).

Когда горутина делает асинхронный системный вызов (например работа с сетью), она отгружается в `netpoller`, который может работать с несколькими горутинами.
![[Pasted image 20250807165003.png]]
???
Взятие новой работы:  

0) 1/61 раза берём горутину из глобальной очереди
1) Пытаемся взять горутину из слота
2) Берём первый элемент из локальной очереди
3) Если локальная очередь пустая, отгружаем горутины из глобальной очереди в локальную (число горутин = размер глобальной очереди / число процессоров + 1)
4) Если глобальная очередь пустая, ищем горутину в `netpoller`
5) Если в `netpoller` пусто, ищем процессор с непустой локальной очередью и воруем половину горутин себе.  
   
**Как работает вытесняющая многозадачность?**
Это метод управления задачами в операционных системах, при котором операционная система управляет выполнением задач (процессов или потоков) и может приостанавливать выполнение одной задачи, чтобы дать время другим задачам. Это обеспечивает более равномерное распределение процессорного времени между задачами и помогает поддерживать отзывчивость системы.

**За счет чего достигается параллельное выполнение в Golang?** 
В Go (или Golang) параллельное выполнение достигается за счет использования **горутины** и **каналов**, а также встроенного планировщика задач в рантайме Go. Эти механизмы позволяют легко и эффективно управлять многопоточностью и параллелизмом.

**В чем разница между вытесняющим и кооперативным планировщиком?** 
Вытесняющий и кооперативный планировщики представляют разные подходы к многозадачности. Вытесняющий планировщик обеспечивает более автоматическое и гибкое управление задачами. Кооперативный планировщик проще в реализации, но требует от задач явного управления временем выполнения, что может привести к проблемам с блокировкой и отзывчивостью системы.

**Кооперативный планировщик** (cooperative scheduler) требует, чтобы каждая задача сама предоставляла управление планировщику, когда она готова передать управление другой задаче. В этом подходе переключение задач происходит только тогда, когда задача явно передает управление планировщику.

**Вытесняющий планировщик** (preemptive scheduler) автоматически управляет переключением задач на основе кванта времени и других факторов, таких как приоритеты задач. Операционная система (ОС) или среда выполнения программ могут приостанавливать выполнение текущей задачи и переключаться на другую задачу в любой момент.

**Можно ли руками переключить контекст горутины?**
В Go контекстное переключение горутин управляется встроенным планировщиком, и разработчики не имеют прямого контроля над этим процессом. Однако, есть способы косвенно повлиять на планирование и переключение контекста горутин.

Функция `runtime.Gosched` позволяет текущей горутине передать управление планировщику, чтобы другие горутины могли получить процессорное время. Это полезно, когда вы хотите сделать паузу в выполнении текущей горутины, чтобы дать возможность другим горутинам работать.

**Может ли горутина начать работу на одном P, приостановиться и продолжить работу на другом P?**
Да, может, если она, например, совершала синхронный `syscall` (вроде даже только в этом случае).

**Может ли одна очередь украсть горутины у другой?**
Да, может, в случае, когда горутин не было в слоте, в своей локальной очереди, в глобальной очереди, в `netpoller` и если есть горутина с непустой локальной очередью, только в этом случае планировщик "крадёт" половину горутин у другой.

**Сколько потоков операционной системы мы можем создать?**
Около 10^4. В теории, операционные системы могут поддерживать создание миллионов потоков, но на практике ограничения зависят от доступных ресурсов и настроек системы. Важно учитывать потребление ресурсов и влияние на производительность при создании большого количества потоков.